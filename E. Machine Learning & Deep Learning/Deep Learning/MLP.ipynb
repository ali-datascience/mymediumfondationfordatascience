{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqActGZy1weq","executionInfo":{"status":"ok","timestamp":1711206293052,"user_tz":-420,"elapsed":36461,"user":{"displayName":"Muhamad Ali","userId":"10299210004429092156"}},"outputId":"0e26a070-efec-4fcc-c6cc-2acccb6bd761"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","4/4 [==============================] - 6s 353ms/step - loss: 1.3856 - accuracy: 0.0000e+00 - val_loss: 1.4369 - val_accuracy: 0.0000e+00\n","Epoch 2/100\n","4/4 [==============================] - 0s 28ms/step - loss: 1.3636 - accuracy: 0.0000e+00 - val_loss: 1.4074 - val_accuracy: 0.0000e+00\n","Epoch 3/100\n","4/4 [==============================] - 0s 31ms/step - loss: 1.3432 - accuracy: 0.0000e+00 - val_loss: 1.3788 - val_accuracy: 0.0000e+00\n","Epoch 4/100\n","4/4 [==============================] - 0s 46ms/step - loss: 1.3231 - accuracy: 0.0093 - val_loss: 1.3514 - val_accuracy: 0.0833\n","Epoch 5/100\n","4/4 [==============================] - 0s 59ms/step - loss: 1.3042 - accuracy: 0.0185 - val_loss: 1.3251 - val_accuracy: 0.1667\n","Epoch 6/100\n","4/4 [==============================] - 0s 68ms/step - loss: 1.2851 - accuracy: 0.0741 - val_loss: 1.3015 - val_accuracy: 0.3333\n","Epoch 7/100\n","4/4 [==============================] - 0s 121ms/step - loss: 1.2670 - accuracy: 0.1574 - val_loss: 1.2782 - val_accuracy: 0.3333\n","Epoch 8/100\n","4/4 [==============================] - 0s 79ms/step - loss: 1.2495 - accuracy: 0.2222 - val_loss: 1.2553 - val_accuracy: 0.4167\n","Epoch 9/100\n","4/4 [==============================] - 0s 81ms/step - loss: 1.2316 - accuracy: 0.2685 - val_loss: 1.2288 - val_accuracy: 0.4167\n","Epoch 10/100\n","4/4 [==============================] - 0s 61ms/step - loss: 1.2134 - accuracy: 0.3148 - val_loss: 1.1995 - val_accuracy: 0.4167\n","Epoch 11/100\n","4/4 [==============================] - 0s 74ms/step - loss: 1.1919 - accuracy: 0.3148 - val_loss: 1.1681 - val_accuracy: 0.4167\n","Epoch 12/100\n","4/4 [==============================] - 0s 51ms/step - loss: 1.1686 - accuracy: 0.3148 - val_loss: 1.1380 - val_accuracy: 0.4167\n","Epoch 13/100\n","4/4 [==============================] - 0s 71ms/step - loss: 1.1457 - accuracy: 0.3148 - val_loss: 1.1110 - val_accuracy: 0.4167\n","Epoch 14/100\n","4/4 [==============================] - 0s 123ms/step - loss: 1.1249 - accuracy: 0.3148 - val_loss: 1.0871 - val_accuracy: 0.4167\n","Epoch 15/100\n","4/4 [==============================] - 0s 66ms/step - loss: 1.1059 - accuracy: 0.3148 - val_loss: 1.0658 - val_accuracy: 0.4167\n","Epoch 16/100\n","4/4 [==============================] - 0s 91ms/step - loss: 1.0879 - accuracy: 0.3148 - val_loss: 1.0470 - val_accuracy: 0.4167\n","Epoch 17/100\n","4/4 [==============================] - 0s 102ms/step - loss: 1.0718 - accuracy: 0.3241 - val_loss: 1.0294 - val_accuracy: 0.4167\n","Epoch 18/100\n","4/4 [==============================] - 0s 87ms/step - loss: 1.0562 - accuracy: 0.3333 - val_loss: 1.0137 - val_accuracy: 0.4167\n","Epoch 19/100\n","4/4 [==============================] - 0s 76ms/step - loss: 1.0416 - accuracy: 0.3796 - val_loss: 0.9991 - val_accuracy: 0.4167\n","Epoch 20/100\n","4/4 [==============================] - 0s 106ms/step - loss: 1.0277 - accuracy: 0.4167 - val_loss: 0.9854 - val_accuracy: 0.5000\n","Epoch 21/100\n","4/4 [==============================] - 0s 136ms/step - loss: 1.0141 - accuracy: 0.5463 - val_loss: 0.9730 - val_accuracy: 0.5000\n","Epoch 22/100\n","4/4 [==============================] - 0s 127ms/step - loss: 1.0013 - accuracy: 0.6204 - val_loss: 0.9614 - val_accuracy: 0.5000\n","Epoch 23/100\n","4/4 [==============================] - 0s 102ms/step - loss: 0.9888 - accuracy: 0.6574 - val_loss: 0.9503 - val_accuracy: 0.5833\n","Epoch 24/100\n","4/4 [==============================] - 0s 100ms/step - loss: 0.9773 - accuracy: 0.6667 - val_loss: 0.9400 - val_accuracy: 0.5833\n","Epoch 25/100\n","4/4 [==============================] - 0s 154ms/step - loss: 0.9667 - accuracy: 0.6667 - val_loss: 0.9303 - val_accuracy: 0.5833\n","Epoch 26/100\n","4/4 [==============================] - 0s 120ms/step - loss: 0.9562 - accuracy: 0.6667 - val_loss: 0.9202 - val_accuracy: 0.5833\n","Epoch 27/100\n","4/4 [==============================] - 0s 81ms/step - loss: 0.9466 - accuracy: 0.6667 - val_loss: 0.9111 - val_accuracy: 0.5833\n","Epoch 28/100\n","4/4 [==============================] - 0s 65ms/step - loss: 0.9374 - accuracy: 0.6667 - val_loss: 0.9035 - val_accuracy: 0.5833\n","Epoch 29/100\n","4/4 [==============================] - 0s 61ms/step - loss: 0.9291 - accuracy: 0.6667 - val_loss: 0.8963 - val_accuracy: 0.5833\n","Epoch 30/100\n","4/4 [==============================] - 0s 53ms/step - loss: 0.9205 - accuracy: 0.6667 - val_loss: 0.8890 - val_accuracy: 0.5833\n","Epoch 31/100\n","4/4 [==============================] - 0s 44ms/step - loss: 0.9126 - accuracy: 0.6667 - val_loss: 0.8817 - val_accuracy: 0.5833\n","Epoch 32/100\n","4/4 [==============================] - 0s 31ms/step - loss: 0.9045 - accuracy: 0.6667 - val_loss: 0.8743 - val_accuracy: 0.5833\n","Epoch 33/100\n","4/4 [==============================] - 0s 66ms/step - loss: 0.8968 - accuracy: 0.6667 - val_loss: 0.8671 - val_accuracy: 0.5833\n","Epoch 34/100\n","4/4 [==============================] - 0s 55ms/step - loss: 0.8890 - accuracy: 0.6667 - val_loss: 0.8597 - val_accuracy: 0.5833\n","Epoch 35/100\n","4/4 [==============================] - 0s 64ms/step - loss: 0.8817 - accuracy: 0.6667 - val_loss: 0.8528 - val_accuracy: 0.5833\n","Epoch 36/100\n","4/4 [==============================] - 0s 30ms/step - loss: 0.8741 - accuracy: 0.6667 - val_loss: 0.8460 - val_accuracy: 0.5833\n","Epoch 37/100\n","4/4 [==============================] - 0s 51ms/step - loss: 0.8667 - accuracy: 0.6667 - val_loss: 0.8391 - val_accuracy: 0.5833\n","Epoch 38/100\n","4/4 [==============================] - 0s 82ms/step - loss: 0.8593 - accuracy: 0.6667 - val_loss: 0.8324 - val_accuracy: 0.5833\n","Epoch 39/100\n","4/4 [==============================] - 0s 48ms/step - loss: 0.8521 - accuracy: 0.6667 - val_loss: 0.8258 - val_accuracy: 0.5833\n","Epoch 40/100\n","4/4 [==============================] - 0s 69ms/step - loss: 0.8450 - accuracy: 0.6667 - val_loss: 0.8196 - val_accuracy: 0.5833\n","Epoch 41/100\n","4/4 [==============================] - 0s 63ms/step - loss: 0.8380 - accuracy: 0.6667 - val_loss: 0.8141 - val_accuracy: 0.5833\n","Epoch 42/100\n","4/4 [==============================] - 0s 41ms/step - loss: 0.8309 - accuracy: 0.6667 - val_loss: 0.8083 - val_accuracy: 0.5833\n","Epoch 43/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.8244 - accuracy: 0.6667 - val_loss: 0.8025 - val_accuracy: 0.5833\n","Epoch 44/100\n","4/4 [==============================] - 0s 82ms/step - loss: 0.8177 - accuracy: 0.6667 - val_loss: 0.7967 - val_accuracy: 0.5833\n","Epoch 45/100\n","4/4 [==============================] - 0s 54ms/step - loss: 0.8111 - accuracy: 0.6667 - val_loss: 0.7917 - val_accuracy: 0.5833\n","Epoch 46/100\n","4/4 [==============================] - 0s 47ms/step - loss: 0.8046 - accuracy: 0.6667 - val_loss: 0.7868 - val_accuracy: 0.5833\n","Epoch 47/100\n","4/4 [==============================] - 0s 47ms/step - loss: 0.7980 - accuracy: 0.6667 - val_loss: 0.7816 - val_accuracy: 0.5833\n","Epoch 48/100\n","4/4 [==============================] - 0s 64ms/step - loss: 0.7915 - accuracy: 0.6667 - val_loss: 0.7764 - val_accuracy: 0.5833\n","Epoch 49/100\n","4/4 [==============================] - 0s 38ms/step - loss: 0.7852 - accuracy: 0.6667 - val_loss: 0.7718 - val_accuracy: 0.5833\n","Epoch 50/100\n","4/4 [==============================] - 0s 45ms/step - loss: 0.7785 - accuracy: 0.6667 - val_loss: 0.7669 - val_accuracy: 0.5833\n","Epoch 51/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.7720 - accuracy: 0.6667 - val_loss: 0.7622 - val_accuracy: 0.5833\n","Epoch 52/100\n","4/4 [==============================] - 0s 56ms/step - loss: 0.7657 - accuracy: 0.6667 - val_loss: 0.7573 - val_accuracy: 0.5833\n","Epoch 53/100\n","4/4 [==============================] - 0s 46ms/step - loss: 0.7591 - accuracy: 0.6667 - val_loss: 0.7518 - val_accuracy: 0.5833\n","Epoch 54/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.7531 - accuracy: 0.6667 - val_loss: 0.7470 - val_accuracy: 0.5833\n","Epoch 55/100\n","4/4 [==============================] - 0s 56ms/step - loss: 0.7466 - accuracy: 0.6667 - val_loss: 0.7416 - val_accuracy: 0.5833\n","Epoch 56/100\n","4/4 [==============================] - 0s 52ms/step - loss: 0.7407 - accuracy: 0.6667 - val_loss: 0.7367 - val_accuracy: 0.5833\n","Epoch 57/100\n","4/4 [==============================] - 0s 121ms/step - loss: 0.7344 - accuracy: 0.6667 - val_loss: 0.7316 - val_accuracy: 0.5833\n","Epoch 58/100\n","4/4 [==============================] - 0s 46ms/step - loss: 0.7279 - accuracy: 0.6667 - val_loss: 0.7280 - val_accuracy: 0.5833\n","Epoch 59/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.7219 - accuracy: 0.6667 - val_loss: 0.7243 - val_accuracy: 0.5833\n","Epoch 60/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.7156 - accuracy: 0.6667 - val_loss: 0.7197 - val_accuracy: 0.5833\n","Epoch 61/100\n","4/4 [==============================] - 0s 67ms/step - loss: 0.7097 - accuracy: 0.6667 - val_loss: 0.7152 - val_accuracy: 0.5833\n","Epoch 62/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.7039 - accuracy: 0.6667 - val_loss: 0.7107 - val_accuracy: 0.5833\n","Epoch 63/100\n","4/4 [==============================] - 0s 46ms/step - loss: 0.6982 - accuracy: 0.6667 - val_loss: 0.7065 - val_accuracy: 0.5833\n","Epoch 64/100\n","4/4 [==============================] - 0s 40ms/step - loss: 0.6922 - accuracy: 0.6667 - val_loss: 0.7018 - val_accuracy: 0.5833\n","Epoch 65/100\n","4/4 [==============================] - 0s 61ms/step - loss: 0.6866 - accuracy: 0.6667 - val_loss: 0.6967 - val_accuracy: 0.5833\n","Epoch 66/100\n","4/4 [==============================] - 0s 76ms/step - loss: 0.6812 - accuracy: 0.6667 - val_loss: 0.6916 - val_accuracy: 0.5833\n","Epoch 67/100\n","4/4 [==============================] - 0s 75ms/step - loss: 0.6756 - accuracy: 0.6759 - val_loss: 0.6867 - val_accuracy: 0.5833\n","Epoch 68/100\n","4/4 [==============================] - 0s 55ms/step - loss: 0.6701 - accuracy: 0.6759 - val_loss: 0.6822 - val_accuracy: 0.5833\n","Epoch 69/100\n","4/4 [==============================] - 0s 50ms/step - loss: 0.6647 - accuracy: 0.6759 - val_loss: 0.6779 - val_accuracy: 0.5833\n","Epoch 70/100\n","4/4 [==============================] - 0s 54ms/step - loss: 0.6593 - accuracy: 0.6759 - val_loss: 0.6734 - val_accuracy: 0.5833\n","Epoch 71/100\n","4/4 [==============================] - 0s 36ms/step - loss: 0.6537 - accuracy: 0.6759 - val_loss: 0.6688 - val_accuracy: 0.5833\n","Epoch 72/100\n","4/4 [==============================] - 0s 18ms/step - loss: 0.6487 - accuracy: 0.6759 - val_loss: 0.6644 - val_accuracy: 0.5833\n","Epoch 73/100\n","4/4 [==============================] - 0s 21ms/step - loss: 0.6434 - accuracy: 0.6759 - val_loss: 0.6607 - val_accuracy: 0.5833\n","Epoch 74/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.6380 - accuracy: 0.6759 - val_loss: 0.6575 - val_accuracy: 0.5833\n","Epoch 75/100\n","4/4 [==============================] - 0s 70ms/step - loss: 0.6327 - accuracy: 0.6759 - val_loss: 0.6546 - val_accuracy: 0.5833\n","Epoch 76/100\n","4/4 [==============================] - 0s 61ms/step - loss: 0.6272 - accuracy: 0.6759 - val_loss: 0.6511 - val_accuracy: 0.5833\n","Epoch 77/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.6216 - accuracy: 0.6759 - val_loss: 0.6486 - val_accuracy: 0.5833\n","Epoch 78/100\n","4/4 [==============================] - 0s 35ms/step - loss: 0.6170 - accuracy: 0.6852 - val_loss: 0.6460 - val_accuracy: 0.5833\n","Epoch 79/100\n","4/4 [==============================] - 0s 43ms/step - loss: 0.6112 - accuracy: 0.6852 - val_loss: 0.6418 - val_accuracy: 0.5833\n","Epoch 80/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.6060 - accuracy: 0.6852 - val_loss: 0.6373 - val_accuracy: 0.5833\n","Epoch 81/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.6008 - accuracy: 0.6852 - val_loss: 0.6330 - val_accuracy: 0.5833\n","Epoch 82/100\n","4/4 [==============================] - 0s 21ms/step - loss: 0.5956 - accuracy: 0.6852 - val_loss: 0.6285 - val_accuracy: 0.5833\n","Epoch 83/100\n","4/4 [==============================] - 0s 14ms/step - loss: 0.5905 - accuracy: 0.6852 - val_loss: 0.6241 - val_accuracy: 0.5833\n","Epoch 84/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.5857 - accuracy: 0.6852 - val_loss: 0.6204 - val_accuracy: 0.5833\n","Epoch 85/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.5806 - accuracy: 0.6944 - val_loss: 0.6164 - val_accuracy: 0.5833\n","Epoch 86/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.5759 - accuracy: 0.6944 - val_loss: 0.6127 - val_accuracy: 0.5833\n","Epoch 87/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.5709 - accuracy: 0.6944 - val_loss: 0.6092 - val_accuracy: 0.5833\n","Epoch 88/100\n","4/4 [==============================] - 0s 13ms/step - loss: 0.5661 - accuracy: 0.6944 - val_loss: 0.6060 - val_accuracy: 0.5833\n","Epoch 89/100\n","4/4 [==============================] - 0s 12ms/step - loss: 0.5614 - accuracy: 0.7222 - val_loss: 0.6027 - val_accuracy: 0.5833\n","Epoch 90/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.5566 - accuracy: 0.7222 - val_loss: 0.5989 - val_accuracy: 0.5833\n","Epoch 91/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.5520 - accuracy: 0.7315 - val_loss: 0.5959 - val_accuracy: 0.5833\n","Epoch 92/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.5479 - accuracy: 0.7315 - val_loss: 0.5938 - val_accuracy: 0.5833\n","Epoch 93/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.5433 - accuracy: 0.7315 - val_loss: 0.5908 - val_accuracy: 0.5833\n","Epoch 94/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.5388 - accuracy: 0.7315 - val_loss: 0.5869 - val_accuracy: 0.6667\n","Epoch 95/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.5347 - accuracy: 0.7407 - val_loss: 0.5833 - val_accuracy: 0.6667\n","Epoch 96/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.5303 - accuracy: 0.7407 - val_loss: 0.5791 - val_accuracy: 0.6667\n","Epoch 97/100\n","4/4 [==============================] - 0s 28ms/step - loss: 0.5266 - accuracy: 0.7407 - val_loss: 0.5757 - val_accuracy: 0.6667\n","Epoch 98/100\n","4/4 [==============================] - 0s 22ms/step - loss: 0.5222 - accuracy: 0.7407 - val_loss: 0.5716 - val_accuracy: 0.6667\n","Epoch 99/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.5185 - accuracy: 0.7407 - val_loss: 0.5685 - val_accuracy: 0.6667\n","Epoch 100/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.5144 - accuracy: 0.7407 - val_loss: 0.5653 - val_accuracy: 0.6667\n","1/1 [==============================] - 0s 37ms/step - loss: 0.4972 - accuracy: 0.7667\n","Test Loss: 0.49720990657806396, Test Accuracy: 0.7666666507720947\n","1/1 [==============================] - 0s 108ms/step\n"]}],"source":["import numpy as np\n","import tensorflow.keras as keras\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","\n","# One-hot encode the target labels\n","encoder = OneHotEncoder(sparse=False)\n","y_one_hot = encoder.fit_transform(y.reshape(-1, 1))\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n","# Define the MLP architecture\n","model = keras.Sequential([\n","    keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n","    keras.layers.Dense(8, activation='relu'),\n","    keras.layers.Dense(3, activation='softmax')  # Output layer with 3 units for 3 classes\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n","\n","# Evaluate the model on the test set\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n","# Predictions\n","predictions = model.predict(X_test)\n"]}]}